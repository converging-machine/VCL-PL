{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rc5E-MOY12I5"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import config\n",
    "from facenet_pytorch import training\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torchvision.models as models\n",
    "#import models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "data_root = \"/home/mehmetyavuz/datasets/CelebA128/\"\n",
    "attr_root = \"/home/mehmetyavuz/datasets/list_attr_celeba.txt\"\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = (128,128)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA(data.Dataset):\n",
    "    def __init__(self, data_path, attr_path, image_size, mode, selected_attrs):\n",
    "        super(CelebA, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        att_list = open(attr_path, 'r', encoding='utf-8').readlines()[1].split()\n",
    "        atts = [att_list.index(att) + 1 for att in selected_attrs]\n",
    "        images = np.loadtxt(attr_path, skiprows=2, usecols=[0], dtype=np.str)\n",
    "        labels = np.loadtxt(attr_path, skiprows=2, usecols=atts, dtype=np.int)\n",
    "        \n",
    "        self.tf = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        if mode == 'train':\n",
    "            self.images = images[:162770]\n",
    "            self.labels = labels[:162770]\n",
    "\n",
    "        if mode == 'valid':\n",
    "            self.images = images[162770:182637]\n",
    "            self.labels = labels[162770:182637]\n",
    "\n",
    "        if mode == 'test':\n",
    "            self.images = images[182637:]\n",
    "            self.labels = labels[182637:]\n",
    "                                       \n",
    "        self.length = len(self.images)\n",
    "    def __getitem__(self, index):\n",
    "        img = self.tf(Image.open(os.path.join(self.data_path, self.images[index])))\n",
    "        att = torch.tensor((self.labels[index] + 1) // 2)\n",
    "        return img, att.to(torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_default = [\"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\", \"Big_Lips\", \"Big_Nose\", \n",
    "                 \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\", \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \n",
    "                 \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \n",
    "                 \"Oval_Face\", \"Pale_Skin\", \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\", \n",
    "                 \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\", \"Wearing_Necktie\", \"Young\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebA(data_root, attr_root, image_size, 'test', attrs_default)\n",
    "test_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=40, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.__dict__['alexnet'](pretrained=False)\n",
    "resnet.classifier[6] = nn.Linear(4096,40,bias=True)\n",
    "resnet = torch.nn.DataParallel(resnet)\n",
    "resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"alexnet_PD_001_0_normal.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resnet = models.__dict__[\"alexnet\"](sobel=True).to(device)\n",
    "resnet.features = nn.DataParallel(resnet.features)\n",
    "\n",
    "weights = torch.load(\"kmeans.pth.tar\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.load_state_dict(weights,strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.FloatTensor(len(dataset), 40)\n",
    "targets = torch.LongTensor(len(dataset),40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "ptr = 0\n",
    "for i, batch in enumerate(test_loader):\n",
    "    images = batch[0].cuda(non_blocking=True)\n",
    "    target = batch[1].cuda(non_blocking=True)\n",
    "    output = resnet(images)\n",
    "    output = nn.Sigmoid()(output)\n",
    "    \n",
    "    b = output.size(0)\n",
    "    \n",
    "    features[ptr:ptr+b].copy_(output.detach())\n",
    "    targets[ptr:ptr+b].copy_(target.detach())\n",
    "    ptr += b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_o_Clock_Shadow ; 0.9056206941604614\n",
      "Arched_Eyebrows ; 0.7786794900894165\n",
      "Attractive ; 0.7748722434043884\n",
      "Bags_Under_Eyes ; 0.8101392388343811\n",
      "Bald ; 0.9782586693763733\n",
      "Bangs ; 0.9403867125511169\n",
      "Big_Lips ; 0.6846007704734802\n",
      "Big_Nose ; 0.8042781352996826\n",
      "Black_Hair ; 0.8489129543304443\n",
      "Blond_Hair ; 0.9433423280715942\n",
      "Blurry ; 0.9499047994613647\n",
      "Brown_Hair ; 0.8495140671730042\n",
      "Bushy_Eyebrows ; 0.8727081418037415\n",
      "Chubby ; 0.9409377574920654\n",
      "Double_Chin ; 0.9527602195739746\n",
      "Eyeglasses ; 0.9717963933944702\n",
      "Goatee ; 0.9526099562644958\n",
      "Gray_Hair ; 0.9719467163085938\n",
      "Heavy_Makeup ; 0.8704037666320801\n",
      "High_Cheekbones ; 0.8173529505729675\n",
      "Male ; 0.9354273080825806\n",
      "Mouth_Slightly_Open ; 0.811491847038269\n",
      "Mustache ; 0.960625171661377\n",
      "Narrow_Eyes ; 0.849263608455658\n",
      "No_Beard ; 0.9008616209030151\n",
      "Oval_Face ; 0.7137561440467834\n",
      "Pale_Skin ; 0.9578198790550232\n",
      "Pointy_Nose ; 0.7153090834617615\n",
      "Receding_Hairline ; 0.9156396985054016\n",
      "Rosy_Cheeks ; 0.9289149641990662\n",
      "Sideburns ; 0.9593226909637451\n",
      "Smiling ; 0.8595331311225891\n",
      "Straight_Hair ; 0.7955615520477295\n",
      "Wavy_Hair ; 0.7968640327453613\n",
      "Wearing_Earrings ; 0.8382426500320435\n",
      "Wearing_Hat ; 0.9792606234550476\n",
      "Wearing_Lipstick ; 0.9044684767723083\n",
      "Wearing_Necklace ; 0.859483003616333\n",
      "Wearing_Necktie ; 0.9478008151054382\n",
      "Young ; 0.8258190751075745\n",
      "Average Accuracy ; 0.8768622875213623\n"
     ]
    }
   ],
   "source": [
    "for i, att in enumerate(attrs_default):\n",
    "    print(att, ';', (targets[:,i] == torch.round(features[:,i])).float().mean().item())\n",
    "print('Average Accuracy ;', (targets == torch.round(features)).float().mean().item())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, att in enumerate(attrs_default):\n",
    "    print(att, ';', roc_auc_score(targets.cpu().numpy()[:,i], features.cpu().numpy()[:,i]))\n",
    "print('Average ROC-AUC;', roc_auc_score(targets.cpu().numpy(), features.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
