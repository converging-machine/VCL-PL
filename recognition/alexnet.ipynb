{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rc5E-MOY12I5"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import config\n",
    "from facenet_pytorch import training\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torchvision.models as models\n",
    "from util import AverageMeter, learning_rate_decay, Logger\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "data_root = \"/home/mehmetyavuz/datasets/CelebA128/\"\n",
    "attr_root = \"/home/mehmetyavuz/datasets/list_attr_celeba.txt\"\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = (128,128)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA(data.Dataset):\n",
    "    def __init__(self, data_path, attr_path, image_size, mode, selected_attrs):\n",
    "        super(CelebA, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        att_list = open(attr_path, 'r', encoding='utf-8').readlines()[1].split()\n",
    "        atts = [att_list.index(att) + 1 for att in selected_attrs]\n",
    "        images = np.loadtxt(attr_path, skiprows=2, usecols=[0], dtype=np.str)\n",
    "        labels = np.loadtxt(attr_path, skiprows=2, usecols=atts, dtype=np.int)\n",
    "        \n",
    "        self.tf = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        self.tf_a = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(0.2),\n",
    "        ])        \n",
    "        if mode == 'train':\n",
    "            self.images = images[:162770]\n",
    "            self.labels = labels[:162770]\n",
    "\n",
    "        if mode == 'valid':\n",
    "            self.images = images[162770:182637]\n",
    "            self.labels = labels[162770:182637]\n",
    "\n",
    "        if mode == 'test':\n",
    "            self.images = images[182637:]\n",
    "            self.labels = labels[182637:]\n",
    "                                       \n",
    "        self.length = len(self.images)\n",
    "    def __getitem__(self, index):\n",
    "        if index < 162770:\n",
    "            img = self.tf(self.tf_a(Image.open(os.path.join(self.data_path, self.images[index]))))\n",
    "        else:\n",
    "            img = self.tf(Image.open(os.path.join(self.data_path, self.images[index])))\n",
    "        att = torch.tensor((self.labels[index] + 1) // 2)\n",
    "        return img, att.to(torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_default = [\"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\", \"Big_Lips\", \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\", \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \"Oval_Face\", \"Pale_Skin\", \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\", \"Wearing_Necktie\", \"Young\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebA(data_root, attr_root, image_size, 'train', attrs_default)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=workers)\n",
    "dataset = CelebA(data_root, attr_root, image_size, 'valid', attrs_default)\n",
    "val_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=workers)\n",
    "dataset = CelebA(data_root, attr_root, image_size, 'test', attrs_default)\n",
    "test_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_n_1=2048, hidden_n_2=400):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc_mu = nn.Linear(hidden_n_1, hidden_n_2)\n",
    "        self.fc_var  = nn.Linear(hidden_n_1, hidden_n_2)\n",
    "        \n",
    "    def reparameterize(self,mu, log_var):\n",
    "        vector_size = log_var.size()\n",
    "        eps = Variable(torch.FloatTensor(vector_size).normal_()).cuda()\n",
    "        std = log_var.mul(0.5).exp_()\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rp = self.reparameterize(self.fc_mu(x), self.fc_var(x))\n",
    "        return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes, sobel):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.top_layer = nn.Linear(4096, num_classes)\n",
    "        self._initialize_weights()\n",
    "        if sobel:\n",
    "            grayscale = nn.Conv2d(3, 1, kernel_size=1, stride=1, padding=0)\n",
    "            grayscale.weight.data.fill_(1.0 / 3.0)\n",
    "            grayscale.bias.data.zero_()\n",
    "            sobel_filter = nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1)\n",
    "            sobel_filter.weight.data[0,0].copy_(\n",
    "                torch.FloatTensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n",
    "            )\n",
    "            sobel_filter.weight.data[1,0].copy_(\n",
    "                torch.FloatTensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "            )\n",
    "            sobel_filter.bias.data.zero_()\n",
    "            self.sobel = nn.Sequential(grayscale, sobel_filter)\n",
    "            for p in self.sobel.parameters():\n",
    "                p.requires_grad = False\n",
    "        else:\n",
    "            self.sobel = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.sobel:\n",
    "            x = self.sobel(x)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        if self.top_layer:\n",
    "            x = self.top_layer(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for y,m in enumerate(self.modules()):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #print(y)\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                for i in range(m.out_channels):\n",
    "                    m.weight.data[i].normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def make_layers(input_dim, batch_norm):\n",
    "    layers = []\n",
    "    in_channels = input_dim\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def vgg16(sobel=False, bn=True, out=40):\n",
    "    dim = 2 + int(not sobel)\n",
    "    model = VGG(make_layers(dim, bn), out, sobel)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = vgg16(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "for i, (name, param) in enumerate(vgg16.named_parameters()):\n",
    "    j = i // 2\n",
    "    if epoch % 2 == 0:\n",
    "        if j % 2 == 0:\n",
    "            if 'weight' in name:\n",
    "                param.requires_grad = False\n",
    "            if 'bias' in name:\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            if 'weight' in name:\n",
    "                param.requires_grad = True\n",
    "            if 'bias' in name:\n",
    "                param.requires_grad = True       \n",
    "    else:\n",
    "        if j % 2 == 0:        \n",
    "            if 'weight' in name:\n",
    "                param.requires_grad = True\n",
    "            if 'bias' in name:\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            if 'weight' in name:\n",
    "                param.requires_grad = False\n",
    "            if 'bias' in name:\n",
    "                param.requires_grad = False         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "features.14.weight\n",
      "features.14.bias\n",
      "features.19.weight\n",
      "features.19.bias\n",
      "features.24.weight\n",
      "features.24.bias\n",
      "features.28.weight\n",
      "features.28.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(vgg16.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.00001)\n",
    "Q = math.floor(len(train_dataset)*epochs)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "metrics = {\n",
    "    'acc': training.accuracy_ml\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, test_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    #writer=writer\n",
    ")\n",
    "\n",
    "val_loss = 1\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        #writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    val_metrics = training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        #writer=writer\n",
    "    )\n",
    "    \n",
    "    if val_metrics[0].item() < val_loss:\n",
    "        val_loss = val_metrics[0].item()\n",
    "        print('Test set Accuracy Lowest Validation Loss:')\n",
    "        training.pass_epoch(\n",
    "            resnet, loss_fn, test_loader,\n",
    "            batch_metrics=metrics, show_running=True, device=device,\n",
    "            #writer=writer\n",
    "        )\n",
    "        torch.save(resnet.state_dict(), \"alexnet.pth\")\n",
    "\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
