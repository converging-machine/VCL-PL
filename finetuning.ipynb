{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rc5E-MOY12I5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import config\n",
    "from facenet_pytorch import training\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torchvision.models as models\n",
    "from util import AverageMeter, learning_rate_decay, Logger\n",
    "from data.celeba import CelebA\n",
    "from utils.config import create_config\n",
    "from utils.collate import collate_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_config(\"configs/env.yml\", \"configs/pretext/pretraining.yml\", 128, 100)\n",
    "p['batch_size'] = 128\n",
    "p['epochs'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(**p['waugmentation_kwargs']['random_resized_crop']),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(**p['waugmentation_kwargs']['color_jitter'])\n",
    "            ], p=p['waugmentation_kwargs']['color_jitter_random_apply']['p']),\n",
    "            transforms.RandomGrayscale(**p['waugmentation_kwargs']['random_grayscale']),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(**p['waugmentation_kwargs']['normalize'])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "                transforms.CenterCrop(p['augmentation_kwargs']['crop_size']),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(**p['augmentation_kwargs']['normalize'])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "data_root = \"/home/mehmetyavuz/datasets/CelebA128/\"\n",
    "attr_root = \"/home/mehmetyavuz/datasets/list_attr_celeba.txt\"\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = (128,128)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.alexnet import alexnet\n",
    "alexnet = alexnet()['backbone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=40, bias=True)\n",
    "alexnet = alexnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/home/mehmetyavuz/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebA(root=folder_name, split='train', transform=transform)\n",
    "#dataset_two = torchvision.datasets.ImageFolder(root='/home/mehmetyavuz/datasets/YFCC392K/', transform=transform)\n",
    "#y_YFCC = np.load('y_YFCC.npy')\n",
    "#dataset_two.targets = y_YFCC\n",
    "#dataset = torch.utils.data.ConcatDataset([dataset_one, dataset_two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, num_workers=p['num_workers'], \n",
    "                batch_size=p['batch_size'], pin_memory=True, collate_fn=collate_custom,\n",
    "                drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_default = [\"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\", \"Big_Lips\", \"Big_Nose\", \n",
    "                 \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\", \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \n",
    "                 \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \n",
    "                 \"Oval_Face\", \"Pale_Skin\", \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\", \n",
    "                 \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\", \"Wearing_Necktie\", \"Young\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebA(root=folder_name, split='valid', transform=val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, num_workers=p['num_workers'],\n",
    "            batch_size=p['batch_size'], pin_memory=True, collate_fn=collate_custom,\n",
    "            drop_last=False, shuffle=False)\n",
    "dataset = CelebA(root=folder_name, split='test', transform=val_transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, num_workers=p['num_workers'],\n",
    "            batch_size=p['batch_size'], pin_memory=True, collate_fn=collate_custom,\n",
    "            drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torch.nn.DataParallel(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"results/CelebA/SimCLR-B128/finetuning_model.pth.tar\")[\"model\"]\n",
    "for key in list(weights.keys()):\n",
    "    weights[key.replace('module.backbone.', 'module.')] = weights.pop(key)\n",
    "    if 'cluster_head' in key:\n",
    "        del weights[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['module.classifier.6.weight', 'module.classifier.6.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet.load_state_dict(weights,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.00001)\n",
    "#Q = math.floor(len(train_dataset)*epochs)\n",
    "scheduler = None #torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "metrics = {\n",
    "    'acc': training.accuracy_ml\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name, param) in enumerate(alexnet.features.named_parameters()):\n",
    "    if ('0.' in name) or ('6.' in name) or ('10.' in name):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "3.weight\n",
      "3.bias\n",
      "6.weight\n",
      "6.bias\n",
      "8.weight\n",
      "8.bias\n",
      "10.weight\n",
      "10.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in alexnet..named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.3.weight\n",
      "features.3.bias\n",
      "features.6.weight\n",
      "features.6.bias\n",
      "features.8.weight\n",
      "features.8.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.4.weight\n",
      "classifier.4.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in alexnet.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "alexnet.eval()\n",
    "training.pass_epoch(\n",
    "    alexnet, loss_fn, test_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    #writer=writer\n",
    ")\n",
    "\n",
    "val_loss = 1\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    alexnet.train()\n",
    "    training.pass_epoch(\n",
    "        alexnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        #writer=writer\n",
    "    )\n",
    "\n",
    "    alexnet.eval()\n",
    "    val_metrics = training.pass_epoch(\n",
    "        alexnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        #writer=writer\n",
    "    )\n",
    "    \n",
    "    if val_metrics[0].item() < val_loss:\n",
    "        val_loss = val_metrics[0].item()\n",
    "        print('Test set Accuracy Lowest Validation Loss:')\n",
    "        training.pass_epoch(\n",
    "            alexnet, loss_fn, test_loader,\n",
    "            batch_metrics=metrics, show_running=True, device=device,\n",
    "            #writer=writer\n",
    "        )\n",
    "        torch.save(alexnet.state_dict(), \"alexnet_ssl.pth\")\n",
    "\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
